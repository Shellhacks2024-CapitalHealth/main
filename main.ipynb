{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import dataFrame as dF\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dataFrame' object has no attribute 'getDataFrame'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key, dataframe \u001b[38;5;129;01min\u001b[39;00m dataframeDic\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame for ID \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, dataframe, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m process_financial_data()\n",
      "Cell \u001b[1;32mIn[34], line 5\u001b[0m, in \u001b[0;36mprocess_financial_data\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_financial_data\u001b[39m():\n\u001b[0;32m      4\u001b[0m     data \u001b[38;5;241m=\u001b[39m dF(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBANKACCOUNTDATA.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m     dataBase \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mgetDataFrame()\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m#Create Dictionary\u001b[39;00m\n\u001b[0;32m      8\u001b[0m     uniqueIDS \u001b[38;5;241m=\u001b[39m dataBase[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccount No\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dataFrame' object has no attribute 'getDataFrame'"
     ]
    }
   ],
   "source": [
    "# Function to process multiple CSV files in a folder\n",
    "def process_financial_data():\n",
    "\n",
    "    dataBase = pd.read_csv(\"BANKACCOUNTDATA.csv\")\n",
    "\n",
    "    #Create Dictionary\n",
    "    uniqueIDS = dataBase['Account No'].unique()\n",
    "    dataframeDic = {}\n",
    "\n",
    "    for Id in uniqueIDS:\n",
    "        individual_df = dataBase[dataBase['Account No'] == Id]\n",
    "        dataframeDic[Id] = individual_df\n",
    "\n",
    "\n",
    "    # Display the individual DataFrames\n",
    "    for key, dataframe in dataframeDic.items():\n",
    "        print(f\"DataFrame for ID {key}:\\n\", dataframe, \"\\n\")\n",
    "\n",
    "process_financial_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GAN**\n",
    "1) Generator (Nueral Net that creates what it thinks is replicated data)\n",
    "2) Discriminator (Nueral Net that is fed both the real and fake data and chooses which one is the most realistis)\n",
    "3) Real/Fake (Sends Back Propogration to the Nueral Nets to edit them depending on the outcome of the Discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Noise for Generator\n",
    "def latent_dim():\n",
    "    #Generate function to optimize randomness\n",
    "    return 10\n",
    "\n",
    "#alpha function for LeakyReLU paramater\n",
    "def alpha():\n",
    "    #Generate function to optimize dying nuerons\n",
    "    return 0.2\n",
    "\n",
    "#input shape function for discriminator\n",
    "def inputShape():\n",
    "    return (people_data[0].columns - 1)\n",
    "\n",
    "#drop paramater for discriminator\n",
    "def dropout():\n",
    "    return 0.3\n",
    "\n",
    "#Define batch size\n",
    "def batch():\n",
    "    return 32\n",
    "\n",
    "#Data values\n",
    "def meanIncome():\n",
    "    return 0\n",
    "\n",
    "def stddevIncome():\n",
    "    return 0\n",
    "\n",
    "def meanExpense():\n",
    "    return 0\n",
    "\n",
    "def stddevExpense():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "def generator(noise):\n",
    "    model = models.Sequential() #Sequential NN\n",
    "    model.add(layers.Dense(128, activation='relu', input_dim=noise))  #Layer of 128 Neurons\n",
    "    model.add(layers.BatchNormalization()) #Normaliztion of previous output layer\n",
    "    model.add(layers.LeakyReLU(alpha=alpha()))  #Correct Dead Neurons\n",
    "    model.add(layers.Dense(256, activation='relu', input_dim=noise))  #Layer of 256 Neurons\n",
    "    model.add(layers.BatchNormalization()) #Normaliztion of previous output layer\n",
    "    model.add(layers.LeakyReLU(alpha=alpha()))  #Correct dead Neurons\n",
    "    model.add(layers.Dense(2, activation = 'tanh')) #Output for income and expense\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discriminator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator\n",
    "def discriminator(inputShape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(256, activation = 'relu', input_shape=inputShape))\n",
    "    model.add(layers.LeakyReLU(alpha=alpha()))\n",
    "    model.add(layers.Dropout(dropout()))    #Dropout layer meaining dropout% of neurons will be ignored\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.LeakyReLU(alpha=alpha()))\n",
    "    model.add(layers.Dropout(dropout()))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))    #sigmoid activation function gives output of 0->1, 1 means real\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defining GAN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = generator()\n",
    "discriminator = discriminator()\n",
    "\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#GAN Model\n",
    "discriminator.trainable = False #Freeze \n",
    "gan_input = layers.Input(shape=(latent_dim()))\n",
    "generated_data = generator(gan_input)\n",
    "gan_output = discriminator(generated_data)\n",
    "gan = models.Model(gan_input, gan_output)\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate Real Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateRealData(batch):\n",
    "    income = np.random.normal(loc = meanIncome(), scale = stddevIncome(), size = batch)\n",
    "    expense = np.random.normal(loc = meanExpense(), scale = stddevExpense(), size = batch)\n",
    "    return np.stack((income, expense), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train GAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(generator, discriminator, gan, latent_dim, epochs, batch_size):\n",
    "    #Training loop\n",
    "    for epoch in range(epochs):\n",
    "        #Generate 'Real Data'\n",
    "        real_data = generateRealData(batch_size)\n",
    "        real_labels = np.ones((batch_size, 1))\n",
    "\n",
    "        #Generate Fake Data\n",
    "        noise = np.random.normal(0,1, (batch_size, latent_dim))\n",
    "        fake_data = generator.predict(noise)\n",
    "        fake_labels = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train discriminator\n",
    "        discriminator_loss_real = discriminator.train_on_batch(real_data, real_labels)\n",
    "        discriminator_loss_fake = discriminator.train_on_batch(fake_data, fake_labels)\n",
    "        discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
    "\n",
    "        # Train generator\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        misleading_labels = np.ones((batch_size, 1))  # Labels for generator training\n",
    "        generator_loss = gan.train_on_batch(noise, misleading_labels)\n",
    "\n",
    "        # Print progress\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
    "\n",
    "#Run training\n",
    "train_gan(generator, discriminator, gan, latent_dim, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
